'use client'

import { Canvas, useFrame } from '@react-three/fiber'

import { playfairDisplay } from '../app/layout'

import { useEffect, useMemo, useRef, useState } from 'react'
import * as THREE from 'three'

export type MediaItem = {
	name: string
	type: 'video' | 'photo'
	url: string
	order: number
}

const ASPECT = 5 / 7

// TODO: —Ü–µ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç —Ç—ñ–ª—å–∫–∏ –¥–ª—è –≤—ñ–¥–µ–æ: —è–∫—â–æ —É –≥–∞–ª–µ—Ä–µ—é –¥–æ–¥–∞–≤–∞—Ç–∏ —Ñ–æ—Ç–æ, —Ç–æ —è–∫—ñ—Å—Ç—å —Ñ–æ—Ç–æ –≤–∏—Ö–æ–¥–∏—Ç—å –≥—ñ—Ä—à–æ—é, –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ç–µ–º–Ω—ñ—à—ñ, –Ω—ñ–∂ —î —É —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—ñ. –î–ª—è —Ñ–æ—Ç–æ–≥–∞–ª–µ—Ä–µ—ó —Ç—Ä–µ–±–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ PhotoGalleryCanvas. –í—ñ–¥—Ä—ñ–∑–Ω—è—î—Ç—å—Å—è –≤—ñ–¥ —Ñ–æ—Ç–æ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è–º–∏ –∫–∞–Ω–≤–∏: –Ω–µ–º–∞—î flat + linear

export default function OldVideoGalleryCanvas({ media }: { media: MediaItem[] }) {
	const containerRef = useRef<HTMLDivElement>(null)
	const canvasWrapperRef = useRef<HTMLDivElement>(null)
	const normalized = useMemo(() => [...media].sort((a, b) => a.order - b.order), [media])
	const [containerWidth, setContainerWidth] = useState(304)
	const [isPlaying, setIsPlaying] = useState(false)

	const [offsetY, setOffsetY] = useState(0)

	useEffect(() => {
		const updateLayout = () => {
			const h = window.innerHeight
			const isMobile = window.matchMedia('(max-width: 768px)').matches

			if (isMobile) {
				// üì± –ú–û–ë–Ü–õ–ö–ê ‚Äî –∑–∞–≤–∂–¥–∏ –º º—è–∫—à–µ
				if (h <= 600) {
					setContainerWidth(304)
					setOffsetY(0)
				} else if (h <= 900) {
					setContainerWidth(320)
					setOffsetY(-20)
				} else {
					setContainerWidth(320)
					setOffsetY(-30)
				}
			} else {
				// üñ• DESKTOP
				if (h <= 400) {
					setContainerWidth(304)
					setOffsetY(50)
				} else if (h <= 700) {
					setContainerWidth(304)
					setOffsetY(20)
				} else if (h <= 900) {
					setContainerWidth(320)
					setOffsetY(-40)
				} else {
					setContainerWidth(340)
					setOffsetY(-80)
				}
			}
		}

		updateLayout()
		window.addEventListener('resize', updateLayout)

		return () => window.removeEventListener('resize', updateLayout)
	}, [])

	return (
		<div
			ref={containerRef}
			className='aspect-5/7 h-auto relative'
			style={{
				width: `${containerWidth}px`,
				transform: `translateY(${offsetY}px)`
			}}
		>
			<div className='w-full h-full overflow-hidden pointer-events-auto relative'>
				<div ref={canvasWrapperRef} className='w-full h-full'>
					<Canvas
						orthographic
						camera={{ zoom: 1, position: [0, 0, 5] }}
						gl={{
							outputColorSpace: THREE.SRGBColorSpace,
							toneMapping: THREE.NoToneMapping
						}}
					>
						<Gallery
							media={normalized}
							containerRef={containerRef}
							setIsPlaying={setIsPlaying} // ‚¨ÖÔ∏è –ù–û–í–ï
						/>
					</Canvas>
				</div>

				{/* <VideoCaption media={normalized} isPlaying={isPlaying} /> */}
			</div>
		</div>
	)
}

function Gallery({
	media,
	containerRef,
	setIsPlaying
}: {
	media: MediaItem[]
	containerRef: React.RefObject<HTMLDivElement | null>
	setIsPlaying: (v: boolean) => void
}) {
	const [currentIndex, setCurrentIndex] = useState(0)
	const [nextIndex, setNextIndex] = useState<number | null>(null)
	const [size, setSize] = useState({ w: 0, h: 0 })
	const [transitionProgress, setTransitionProgress] = useState(0)
	const [textures, setTextures] = useState<THREE.Texture[]>([])
	const animationSpeed = 0.05

	// ‚¨ÖÔ∏è —â–æ–± –Ω–µ –≤–∏–∫–ª–∏–∫–∞—Ç–∏ setIsPlaying –±–∞–≥–∞—Ç–æ —Ä–∞–∑—ñ–≤
	const playingReportedRef = useRef(false)

	// 1Ô∏è‚É£ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ç–µ–∫—Å—Ç—É—Ä
	useEffect(() => {
		if (media.length === 0) return

		const loader = new THREE.TextureLoader()
		const texs: THREE.Texture[] = []
		const videos: HTMLVideoElement[] = []

		const loadAll = async () => {
			for (let i = 0; i < media.length; i++) {
				const item = media[i]

				if (item.type === 'photo') {
					const texture = await loader.loadAsync(item.url)
					texture.colorSpace = THREE.SRGBColorSpace
					texture.needsUpdate = true
					texs.push(texture)

					// —è–∫—â–æ –ø–µ—Ä—à–∏–π –µ–ª–µ–º–µ–Ω—Ç ‚Äî —Ñ–æ—Ç–æ, –º–æ–∂–Ω–∞ –≤–≤–∞–∂–∞—Ç–∏ –≥–æ—Ç–æ–≤–∏–º –æ–¥—Ä–∞–∑—É
					if (i === 0 && !playingReportedRef.current) {
						playingReportedRef.current = true
						setIsPlaying(true)
					}
				} else {
					const video = document.createElement('video')
					video.src = item.url
					video.crossOrigin = 'anonymous'
					video.loop = true
					video.muted = true
					video.playsInline = true
					video.preload = 'auto'

					if (i === 0) {
						video.requestVideoFrameCallback(() => {
							if (!playingReportedRef.current) {
								playingReportedRef.current = true
								setIsPlaying(true)
							}
						})
					}

					await video.play().catch(() => {})
					const texture = new THREE.VideoTexture(video)

					texs.push(texture)
					videos.push(video)
				}
			}

			setTextures(texs)
		}

		loadAll()

		return () => {
			texs.forEach(tex => tex?.dispose())
			videos.forEach(video => {
				video.pause()
				video.src = ''
				video.load()
			})
		}
	}, [media, setIsPlaying])

	// 2Ô∏è‚É£ Click navigation
	useEffect(() => {
		const onClick = (e: MouseEvent) => {
			if (nextIndex !== null) return
			if (e.clientX < window.innerWidth / 2) {
				setNextIndex((currentIndex - 1 + media.length) % media.length)
			} else {
				setNextIndex((currentIndex + 1) % media.length)
			}
		}
		window.addEventListener('click', onClick)
		return () => window.removeEventListener('click', onClick)
	}, [currentIndex, nextIndex, media.length])

	// 3Ô∏è‚É£ Resize
	useEffect(() => {
		if (!containerRef.current) return
		const el = containerRef.current
		const update = () => {
			const w = el.clientWidth
			const h = w / ASPECT
			setSize({ w, h })
		}
		update()
		const ro = new ResizeObserver(update)
		ro.observe(el)
		return () => ro.disconnect()
	}, [containerRef])

	// 4Ô∏è‚É£ Transition animation
	useFrame(() => {
		if (nextIndex !== null) {
			setTransitionProgress(p => {
				const nextP = p + animationSpeed
				if (nextP >= 1) {
					setCurrentIndex(nextIndex)
					setNextIndex(null)
					return 0
				}
				return nextP
			})
		}
	})

	// 5Ô∏è‚É£ Cursor
	useEffect(() => {
		const onMouseMove = (e: MouseEvent) => {
			if (e.clientX < window.innerWidth / 2) {
				document.body.style.cursor = 'url(/images/left.png) 16 16, auto'
			} else {
				document.body.style.cursor = 'url(/images/right.png) 16 16, auto'
			}
		}
		window.addEventListener('mousemove', onMouseMove)
		return () => {
			window.removeEventListener('mousemove', onMouseMove)
			document.body.style.cursor = 'auto'
		}
	}, [])

	return (
		<>
			{textures[currentIndex] && size.w > 0 && (
				<mesh>
					<planeGeometry args={[size.w, size.h]} />
					<meshBasicMaterial map={textures[currentIndex]} toneMapped={false} />
				</mesh>
			)}

			{nextIndex !== null && textures[nextIndex] && size.w > 0 && (
				<mesh>
					<planeGeometry args={[size.w, size.h]} />
					<meshBasicMaterial
						map={textures[nextIndex]}
						opacity={transitionProgress}
						transparent
						toneMapped={false}
					/>
				</mesh>
			)}
		</>
	)
}

function VideoCaption({ media, isPlaying }: { media: MediaItem[]; isPlaying: boolean }) {
	const [index, setIndex] = useState(0)

	useEffect(() => {
		const onClick = (e: MouseEvent) => {
			if (e.clientX < window.innerWidth / 2) {
				setIndex(prev => (prev - 1 + media.length) % media.length)
			} else {
				setIndex(prev => (prev + 1) % media.length)
			}
		}
		window.addEventListener('click', onClick)
		return () => window.removeEventListener('click', onClick)
	}, [media.length])

	// ‚¨ÖÔ∏è –Ñ–î–ò–ù–ê –£–ú–û–í–ê
	if (!isPlaying) return null

	return (
		<div className='w-77.5 mt-6'>
			<p
				className={`min-h-3.5 text-sm text-center xl:text-left w-full tracking-3 leading-none ${playfairDisplay.className}`}
			>
				{media[index]?.name}
			</p>
		</div>
	)
}
